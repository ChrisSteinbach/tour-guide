name: Build Data Pipeline

on:
  workflow_dispatch:
    inputs:
      langs:
        description: 'Languages to process (JSON array, e.g. ["sv"])'
        default: '["en", "sv", "ja"]'
        type: string
  schedule:
    # Monthly on the 1st at 03:00 UTC
    - cron: "0 3 1 * *"

permissions:
  contents: write

jobs:
  build-data:
    runs-on: ubuntu-latest
    # First uncached extraction can take hours; cached runs are much faster
    timeout-minutes: 480

    strategy:
      matrix:
        lang: ${{ fromJSON(inputs.langs || '["en", "sv", "ja"]') }}
      max-parallel: 1

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: npm

      - run: npm ci

      - name: Restore extraction checkpoint
        uses: actions/cache/restore@v4
        with:
          path: |
            data/checkpoint-${{ matrix.lang }}.json
            data/articles-${{ matrix.lang }}.json
          key: extract-${{ matrix.lang }}-${{ github.run_id }}
          restore-keys: extract-${{ matrix.lang }}-

      - name: Restore tile cache
        uses: actions/cache@v4
        with:
          path: data/tile-cache-${{ matrix.lang }}.json
          key: tile-cache-v1-${{ matrix.lang }}

      - name: Extract articles from Wikidata
        run: npm run extract -- --lang=${{ matrix.lang }}

      - name: Build triangulation data
        run: npm run pipeline -- --lang=${{ matrix.lang }}

      - name: Compress data files
        run: gzip --keep data/articles-${{ matrix.lang }}.json data/triangulation-${{ matrix.lang }}.bin

      - name: Upload data artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-data-${{ matrix.lang }}-${{ github.run_id }}
          path: |
            data/articles-${{ matrix.lang }}.json.gz
            data/triangulation-${{ matrix.lang }}.bin.gz
            data/tile-cache-${{ matrix.lang }}.json
          retention-days: 90

      - name: Save extraction checkpoint
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            data/checkpoint-${{ matrix.lang }}.json
            data/articles-${{ matrix.lang }}.json
          key: extract-${{ matrix.lang }}-${{ github.run_id }}

  publish-release:
    needs: build-data
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          pattern: pipeline-data-*

      - name: Download existing release assets
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p data
          gh release download data-latest --dir data --pattern 'triangulation-*.bin.gz' || true

      - name: Merge with newly built files
        run: |
          # Overwrite only the languages that were rebuilt
          cp artifacts/*/triangulation-*.bin.gz data/

      - name: Publish data release
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh release delete data-latest --yes --cleanup-tag || true
          gh release create data-latest \
            --title "Pipeline Data ($(date -u +%Y-%m-%d))" \
            --notes "Auto-generated by pipeline workflow" \
            data/triangulation-*.bin.gz
